spark.hadoop.mapreduce.fileoutputcommitter.cleanup.skipped true
fs.azure.account.oauth2.client.secret ow.E8BaP5-~2KDJz-A5.9meUEefP6gtZuZ
spark.sql.parquet.compression.codec snappy
spark.databricks.io.parquet.fastwriter.enabled true
spark.databricks.delta.preview.enabled false
fs.azure.account.oauth2.client.endpoint https://login.microsoftonline.com/6ac7a1f4-5fb1-4153-bb4f-12d2020a1f7d/oauth2/token
spark.databricks.clusterUsageTags.clusterAggressiveAutoscalingWindowDownSeconds 300
datanucleus.fixedDatastore false
spark.hadoop.fs.azure.account.oauth2.client.secret ow.E8BaP5-~2KDJz-A5.9meUEefP6gtZuZ
spark.databricks.downloadToExecutorDir.enabled false
spark.sql.sources.partitionOverwriteMode dynamic
fs.azure.account.oauth2.client.id b55c24bf-f8b3-44ce-a9ba-8e029ee5b3ff
spark.databricks.io.cache.enabled false
spark.databricks.io.parquet.nativeReader.enabled true
spark.hadoop.fs.azure.account.oauth2.client.endpoint https://login.microsoftonline.com/6ac7a1f4-5fb1-4153-bb4f-12d2020a1f7d/oauth2/token
spark.sql.shuffle.partitions 200
fs.azure.account.key.osaeuuat.blob.core.windows.net eybLcvlpMu+Tv7O4SyXzY09JoJW5HazW3DNmZAeIrFgW1zbuELFwjNDrj/8F2cfuNtuGIVeReL90+AStMF11Hw==
spark.sql.warehouse.dir abfss://osa@cseunproduatprocessing.dfs.core.windows.net/eu_uat/hive
datanucleus.autoCreateSchema true
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2
spark.hadoop.parquet.block.size 134217728
spark.hadoop.fs.azure.account.oauth2.client.id b55c24bf-f8b3-44ce-a9ba-8e029ee5b3ff
hive.exec.dynamic.partition.mode nonstrict
spark.executor.extraJavaOptions -XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=32M -XX:ReservedCodeCacheSize=256m -XX:+UseCodeCacheFlushing -Ddatabricks.serviceName=spark-executor-1 -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xss4m -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl
spark.hadoop.fs.azure.account.auth.type OAuth
spark.hadoop.fs.azure.account.oauth.provider.type org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
spark.sql.hive.metastore.version 2.3.9
spark.sql.adaptive.enabled true
spark.hadoop.dfs.adls.oauth2.client.id a5cde907-8ee6-4110-9804-c28b3d2d4029
spark.hadoop.dfs.adls.oauth2.credential ow.E8BaP5-~2KDJz-A5.9meUEefP6gtZuZ
hive.exec.dynamic.partition true
fs.azure.account.oauth.provider.type org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
fs.azure.account.auth.type OAuth
spark.hadoop.hive.metastore.uris thrift://10.210.16.4:9083
HADOOP_USER_NAME a098078682e84c72a85136374f0d1641